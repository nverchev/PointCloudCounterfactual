# User settings for replicating the experiments

seed:  # random seed

# Options for training efficiency (should not impact the training of the model)
cpu: false  # false enables acceleration
n_workers: 0  # 0 means that the data will be loaded in the main process
n_parallel_training_processes: 0  # number of processes used for training
checkpoint_every: 100  # save a checkpoint of the model after every n epochs
load_checkpoint: 0  # load a checkpoint from the experiments folder, -1 indicates loading the latest checkpoint

# Options for logging
path:
    exp_par_dir: experiments/${version}/  # main folder for storing experiments

trackers:   # optional trackers for monitoring the experiment
  hydra: true  # saves a local copy of the config file
  tensorboard: true  # start a tensorboard server and log metrics
  wandb: false  # logs metrics to wandb
  sqlalchemy: false  # saves metrics to a local database
  csv: true  # saves metrics to a csv file

# Options for counterfactual generation (will affect the results)
counterfactual_value: 1  # value associated with the counterfactual evaluation (the larger, the bigger the change)
n_generated_output_points: ${autoencoder.architecture.training_output_points}  # number of output points generated

# options for generating samples (for visualization only)
generate:
  batch_size: 16  # number of samples to generate when visualizing reconstructions or counterfactuals
  bias_dim: 0   # insert a bias term in the latent space
  bias_value: 0.  # value of the bias term

# options for plotting
plot:
    interactive: false  # use plotly on the browser to visualize the results
    indices_to_reconstruct: [0, 9, 16, 20, 25, 34, 39, 44, 46, 66, 91, 98]  # indices of the clouds to reconstruct
    double_encoding: false  # reconstruct the point cloud input from the continuous latent space

